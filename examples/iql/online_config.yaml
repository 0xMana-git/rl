# Task and env
env:
  env_name: Pendulum-v1
  env_task: ""
  env_library: gym
  record_video: 0
  normalize_rewards_online: 0
  normalize_rewards_online_scale: 5
  normalize_rewards_online_decay: 0.99
  n_samples_stats: 1000
  frame_skip: 1
  from_pixels: False
  num_envs: 1
  reward_scaling:
  noop: 1
  seed: 0

# Collector
collector:
  async_collection: 1
  frames_per_batch: 1000
  total_frames: 1000000 
  multi_step: 0
  init_random_frames: 5000
  collector_devices: cpu
  num_collectors: 1
  max_frames_per_traj: 1000

# Eval
recorder:
  video: False
  interval: 10000 # record interval in frames
  frames: 10000

# logger
logger:
  backend: wandb
  exp_name: iql_pendulum_gym

# Buffer
replay_buffer:
  prb: 0
  buffer_prefetch: 64
  capacity: 1_000_000

# Optimization
optim:
  device: cpu
  lr: 3e-4
  weight_decay: 0.0
  batch_size: 256
  lr_scheduler: ""
  optim_steps_per_batch: 1000
  policy_update_delay: 2

# Policy and model
model:
  activation: relu
  default_policy_scale: 1.0
  scale_lb: 0.1

# loss
loss: 
  loss_function: smooth_l1
  gamma: 0.99
  tau: 0.05
  # IQL hyperparameter
  temperature: 3.0
  expectile: 0.7
